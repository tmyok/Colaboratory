{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-onnx-export.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtwNaX7pK1pFX1AZ+cqNJI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmyok/Colaboratory/blob/master/pytorch_onnx_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wipNo1V28P8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "6bcdf7ca-cc8b-41cc-b428-2b9bfacee373"
      },
      "source": [
        "!pip install onnxruntime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting onnxruntime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/39/404df5ee608c548dacde43a17faf0248b183fa6163cf9c06aca6a511d760/onnxruntime-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.6/dist-packages (from onnxruntime) (1.18.4)\n",
            "Collecting onnx>=1.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/ee/bc7bc88fc8449266add978627e90c363069211584b937fd867b0ccc59f09/onnx-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx>=1.2.3->onnxruntime) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx>=1.2.3->onnxruntime) (3.6.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx>=1.2.3->onnxruntime) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx>=1.2.3->onnxruntime) (46.3.0)\n",
            "Installing collected packages: onnx, onnxruntime\n",
            "Successfully installed onnx-1.7.0 onnxruntime-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSuyrk7cbXns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b579951c-6b6e-4daa-abec-4bd3df3116b7"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import onnxruntime\n",
        "\n",
        "print(\"numpy: \", np.__version__)\n",
        "print(\"torch: \", torch.__version__)\n",
        "print(\"onnxruntime: \", onnxruntime.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy:  1.18.4\n",
            "torch:  1.5.0+cu101\n",
            "onnxruntime:  1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Vdtyl-jc8eq",
        "colab_type": "text"
      },
      "source": [
        "Verify that ONNX Runtime and PyTorch are computing the same value for the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6luNjlVf9Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def verify_onnx_export(pytorch_model):\n",
        "\n",
        "  def to_numpy(tensor):\n",
        "      return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "  \n",
        "  # Input to the model\n",
        "  torch_in = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "  # compute PyTorch output prediction\n",
        "  pytorch_model.eval()\n",
        "  torch_out = pytorch_model(torch_in)\n",
        "\n",
        "  # Export the model\n",
        "  torch.onnx.export(pytorch_model, torch_in, \"sample.onnx\", opset_version=11)\n",
        "  \n",
        "  # compute ONNX Runtime output prediction\n",
        "  ort_session = onnxruntime.InferenceSession(\"sample.onnx\")\n",
        "  ort_outs = ort_session.run(None, {ort_session.get_inputs()[0].name: to_numpy(torch_in)})\n",
        "\n",
        "  # compare ONNX Runtime and PyTorch results\n",
        "  np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "  print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOwHguU2d4tw",
        "colab_type": "text"
      },
      "source": [
        "First step: simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt4Ik738-UIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51f47274-462a-47a1-a45e-4b29ca952992"
      },
      "source": [
        "class ModelC(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ModelC, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels,  kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv(x)\n",
        "        return y\n",
        "\n",
        "verify_onnx_export(ModelC(in_channels=3, out_channels=64))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDI-JZP5eLVq",
        "colab_type": "text"
      },
      "source": [
        "Conv + Bn + Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebGl30AM8dBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd9ac0cf-2899-47f7-8f17-31bad305a92d"
      },
      "source": [
        "class ModelCBR(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ModelCBR, self).__init__()\n",
        "\n",
        "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels,  kernel_size=3, stride=1, padding=1)\n",
        "        self.bn = torch.nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = torch.nn.functional.relu(self.bn(self.conv(x)))\n",
        "        return y\n",
        "\n",
        "verify_onnx_export(ModelCBR(in_channels=3, out_channels=64))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsC9q3U3eQX0",
        "colab_type": "text"
      },
      "source": [
        "CBR*2 + Pool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "andxpgnTGu7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3ddf5ea-5393-44bc-f2f8-654c9d83e56b"
      },
      "source": [
        "class ModelCBR2P(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ModelCBR2P, self).__init__()\n",
        "\n",
        "        self.layer1 = ModelCBR(in_channels=in_channels, out_channels=out_channels)\n",
        "        self.layer2 = ModelCBR(in_channels=out_channels, out_channels=out_channels)\n",
        "        self.pool = torch.nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.pool(self.layer2(self.layer1(x)))\n",
        "        return y\n",
        "\n",
        "verify_onnx_export(ModelCBR2P(in_channels=3, out_channels=64))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2YCbdjbeWhP",
        "colab_type": "text"
      },
      "source": [
        "Simple encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVeOX90YIuVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7f7d136-11ed-4b37-a5ff-3f1c8542034f"
      },
      "source": [
        "class EncoderD4(torch.nn.Module):\n",
        "    def __init__(self, in_channels, base_channel_size):\n",
        "        super(EncoderD4, self).__init__()\n",
        "\n",
        "        module1_channel_size = base_channel_size\n",
        "        module2_channel_size = base_channel_size * 2\n",
        "        module3_channel_size = base_channel_size * 4\n",
        "        module4_channel_size = base_channel_size * 8\n",
        "        self.module1 = ModelCBR2P(in_channels=in_channels, out_channels=module1_channel_size)\n",
        "        self.module2 = ModelCBR2P(in_channels=module1_channel_size, out_channels=module2_channel_size)\n",
        "        self.module3 = ModelCBR2P(in_channels=module2_channel_size, out_channels=module3_channel_size)\n",
        "        self.module4 = ModelCBR2P(in_channels=module3_channel_size, out_channels=module4_channel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.module1(x)\n",
        "        h2 = self.module2(h1)\n",
        "        h3 = self.module3(h2)\n",
        "        y = self.module4(h3)\n",
        "        return y\n",
        "\n",
        "verify_onnx_export(EncoderD4(in_channels=3, base_channel_size=64))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNnK8koVefnH",
        "colab_type": "text"
      },
      "source": [
        "CBR*2 + Upsample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X31K74DCJ_Rq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4d84230-b5ec-49b5-ae07-4577d3490829"
      },
      "source": [
        "class ModelCBR2UP(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ModelCBR2UP, self).__init__()\n",
        "\n",
        "        self.layer1 = ModelCBR(in_channels=in_channels, out_channels=out_channels)\n",
        "        self.layer2 = ModelCBR(in_channels=out_channels, out_channels=out_channels)\n",
        "        self.up = torch.nn.UpsamplingNearest2d(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.up(self.layer2(self.layer1(x)))\n",
        "        return y\n",
        "\n",
        "verify_onnx_export(ModelCBR2UP(in_channels=3, out_channels=64))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDVWp1gmejTZ",
        "colab_type": "text"
      },
      "source": [
        "Simple decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDje2aPd07kG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderU4(torch.nn.Module):\n",
        "    def __init__(self, in_channels, base_channel_size):\n",
        "        super(DecoderU4, self).__init__()\n",
        "\n",
        "        module4_channel_size = base_channel_size * 8\n",
        "        module3_channel_size = base_channel_size * 4\n",
        "        module2_channel_size = base_channel_size * 2\n",
        "        module1_channel_size = base_channel_size\n",
        "        self.module4 = ModelCBR2UP(in_channels=module4_channel_size, out_channels=module3_channel_size)\n",
        "        self.module3 = ModelCBR2UP(in_channels=module3_channel_size, out_channels=module2_channel_size)\n",
        "        self.module2 = ModelCBR2UP(in_channels=module2_channel_size, out_channels=module1_channel_size)\n",
        "        self.module1 = ModelCBR2UP(in_channels=module1_channel_size, out_channels=in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.module4(x)\n",
        "        h2 = self.module3(h1)\n",
        "        h3 = self.module2(h2)\n",
        "        y = self.module1(h3)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqGf3Wzmelsv",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKWtbvM169p7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "120b0798-69af-4208-92fc-9cae3ee8adda"
      },
      "source": [
        "class AutoEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, base_channel_size):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.Encoder = EncoderD4(in_channels=3, base_channel_size=64)\n",
        "        self.Decoder = DecoderU4(in_channels=3, base_channel_size=64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.Decoder(self.Encoder(x))\n",
        "        return y\n",
        "\n",
        "verify_onnx_export(AutoEncoder(in_channels=3, base_channel_size=64))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDPTq6Z-eoin",
        "colab_type": "text"
      },
      "source": [
        "Variational autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXPibK8ESRMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfb3f622-db04-4a0a-8506-8c54107d595d"
      },
      "source": [
        "class VAE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, base_channel_size):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.Encoder = EncoderD4(in_channels=3, base_channel_size=64)\n",
        "        self.Decoder = DecoderU4(in_channels=3, base_channel_size=64)\n",
        "\n",
        "        # latent\n",
        "        feature_size = nz = base_channel_size * 8\n",
        "        self.mu_cnv = torch.nn.Conv2d(in_channels=feature_size, out_channels=nz, kernel_size=1, stride=1, padding=0)\n",
        "        self.logvar_cnv = torch.nn.Conv2d(in_channels=feature_size, out_channels=nz, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def latent(self, x):\n",
        "        return self.mu_cnv(x), self.logvar_cnv(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu# + eps*std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.latent(self.Encoder(x))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        y = self.Decoder(z)\n",
        "        return y\n",
        "\n",
        "verify_onnx_export(VAE(in_channels=3, base_channel_size=64))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}